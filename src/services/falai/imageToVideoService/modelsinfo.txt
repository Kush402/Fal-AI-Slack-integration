1)fal-ai/veo2/image-to-video
About
Generate videos by animating an input image using Google's Veo 2 model.

The prompt should describe how to animate the input image. Include:

Action: How the image should be animated
Style: Desired animation style
Camera motion (optional): How camera should move
Ambiance (optional): Desired mood and atmosphere
More details are available in our prompting guide.

The model supports:

Input images up to 8MB in size
720p output resolution
Both 16:9 (landscape) and 9:16 (portrait) aspect ratios
Natural motion and realistic animations
Control over animation via text prompts
Safety filters are applied to both input images and generated content.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/veo2/image-to-video", {
  input: {
    prompt: "A lego chef cooking eggs",
    image_url: "https://fal.media/files/elephant/6fq8JDSjb1osE_c3J_F2H.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/veo2/image-to-video", {
  input: {
    prompt: "A lego chef cooking eggs",
    image_url: "https://fal.media/files/elephant/6fq8JDSjb1osE_c3J_F2H.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/veo2/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/veo2/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt describing how the image should be animated

image_url string
URL of the input image to animate. Should be 720p or higher resolution.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "auto"

Possible enum values: auto, auto_prefer_portrait, 16:9, 9:16

duration DurationEnum
The duration of the generated video in seconds Default value: "5s"

Possible enum values: 5s, 6s, 7s, 8s


{
  "prompt": "A lego chef cooking eggs",
  "image_url": "https://fal.media/files/elephant/6fq8JDSjb1osE_c3J_F2H.png",
  "aspect_ratio": "auto",
  "duration": "5s"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/monkey/jOYy3rvGB33vumzulpXd5_output.mp4"
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

2)fal-ai/wan-pro/image-to-video
About
Generate a 6-second 1080p video (at 30 FPS) from an image and text using an enhanced version of Wan 2.1.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/wan-pro/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
    image_url: "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/wan-pro/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
    image_url: "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/wan-pro/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/wan-pro/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate the video

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

enable_safety_checker boolean
Whether to enable the safety checker Default value: true

image_url string
The URL of the image to generate the video from


{
  "prompt": "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
  "enable_safety_checker": true,
  "image_url": "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://fal.media/files/kangaroo/K1hB3k-IXBzq9rz1kNOxy.mp4"
  }
}
Other types
#
WanProT2VResponse
#
video File
The generated video

WanProT2VRequest
#
prompt string
The prompt to generate the video

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

enable_safety_checker boolean
Whether to enable the safety checker Default value: true

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

3)fal-ai/kling-video/v2.1/standard/image-to-video
About
Kling 2.1 (std) Image to Video API.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/v2.1/standard/image-to-video", {
  input: {
    prompt: "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
    image_url: "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kling-video/v2.1/standard/image-to-video", {
  input: {
    prompt: "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
    image_url: "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kling-video/v2.1/standard/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kling-video/v2.1/standard/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5


{
  "prompt": "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
  "image_url": "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp",
  "duration": "5",
  "negative_prompt": "blur, distort, and low quality",
  "cfg_scale": 0.5
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/panda/aIxNQwcs5syCT5sYT5_HB_output.mp4"
  }
}
Other types
#
TextToVideoV21MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

V1TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

camera_control CameraControlEnum
Camera control parameters

Possible enum values: down_back, forward_up, right_turn_forward, left_turn_forward

advanced_camera_control CameraControl
Advanced Camera control parameters

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ProImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

tail_image_url string
URL of the image to be used for the end of the video

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncA2VRequest
#
video_url string
The URL of the video to generate the lip sync for.

audio_url string
The URL of the audio to generate the lip sync for.

ImageToVideoV21MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

CameraControl
#
movement_type MovementTypeEnum
The type of camera movement

Possible enum values: horizontal, vertical, pan, tilt, roll, zoom

movement_value integer
The value of the camera movement

ImageToVideoV21ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncT2VRequest
#
video_url string
The URL of the video to generate the lip sync for.

text string
Text content for lip-sync video generation. Max 120 characters.

voice_id VoiceIdEnum
Voice ID to use for speech synthesis

Possible enum values: genshin_vindi2, zhinen_xuesheng, AOT, ai_shatang, genshin_klee2, genshin_kirara, ai_kaiya, oversea_male1, ai_chenjiahao_712, girlfriend_4_speech02, chat1_female_new-3, chat_0407_5-1, cartoon-boy-07, uk_boy1, cartoon-girl-01, PeppaPig_platform, ai_huangzhong_712, ai_huangyaoshi_712, ai_laoguowang_712, chengshu_jiejie, you_pingjing, calm_story1, uk_man2, laopopo_speech02, heainainai_speech02, reader_en_m-v1, commercial_lady_en_f-v1, tiyuxi_xuedi, tiexin_nanyou, girlfriend_1_speech02, girlfriend_2_speech02, zhuxi_speech02, uk_oldman3, dongbeilaotie_speech02, chongqingxiaohuo_speech02, chuanmeizi_speech02, chaoshandashu_speech02, ai_taiwan_man2_speech02, xianzhanggui_speech02, tianjinjiejie_speech02, diyinnansang_DB_CN_M_04-v2, yizhipiannan-v1, guanxiaofang-v2, tianmeixuemei-v1, daopianyansang-v1, mengwa-v1

voice_language VoiceLanguageEnum
The voice language corresponding to the Voice ID Default value: "en"

Possible enum values: zh, en

voice_speed float
Speech rate for Text to Video generation Default value: 1

V1ImageToVideoRequest
#
prompt string
The prompt for the video

image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

static_mask_url string
URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)

dynamic_masks list<DynamicMask>
List of dynamic masks

DynamicMask
#
mask_url string
URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)

trajectories list<Trajectory>
List of trajectories

TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

VideoEffectsRequest
#
input_image_urls list<string>
URL of images to be used for hug, kiss or heart_gesture video.

effect_scene EffectSceneEnum
The effect scene to use for the video generation

Possible enum values: hug, kiss, heart_gesture, squish, expansion, fuzzyfuzzy, bloombloom, dizzydizzy

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

MultiImageToVideoRequest
#
prompt string
input_image_urls list<string>
List of image URLs to use for video generation. Supports up to 4 images.

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

TextToVideoV2MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

Trajectory
#
x integer
X coordinate of the motion trajectory

y integer
Y coordinate of the motion trajectory

ImageToVideoV2MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

4)fal-ai/bytedance/seedance/v1/lite/image-to-video
About
Generate videos from an image and text using Bytedance's Seedance 1.0 Lite model.

This endpoint allows you to provide a starting image frame along with a text prompt to generate a video. The model will animate the image based on the text description. You can optionally keep the original aspect ratio of the input image.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/bytedance/seedance/v1/lite/image-to-video", {
  input: {
    prompt: "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden.",
    image_url: "https://fal.media/files/koala/f_xmiodPjhiKjdBkFmTu1.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/bytedance/seedance/v1/lite/image-to-video", {
  input: {
    prompt: "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden.",
    image_url: "https://fal.media/files/koala/f_xmiodPjhiKjdBkFmTu1.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/bytedance/seedance/v1/lite/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/bytedance/seedance/v1/lite/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt used to generate the video

resolution ResolutionEnum
Video resolution - 480p for faster generation, 720p for higher quality Default value: "720p"

Possible enum values: 480p, 720p, 1080p

duration DurationEnum
Duration of the video in seconds Default value: "5"

Possible enum values: 5, 10

camera_fixed boolean
Whether to fix the camera position

seed integer
Random seed to control video generation. Use -1 for random.

image_url string
The URL of the image used to generate video

end_image_url string
The URL of the image the video ends with. Defaults to None.


{
  "prompt": "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden.",
  "resolution": "720p",
  "duration": "5",
  "image_url": "https://fal.media/files/koala/f_xmiodPjhiKjdBkFmTu1.png"
}
Output
#
video File
Generated video file

seed integer
Seed used for generation


{
  "video": {
    "url": "https://v3.fal.media/files/penguin/qmLZSvOIzTKs6bDFXiEtH_video.mp4"
  },
  "seed": 42
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

5)fal-ai/minimax/hailuo-02/pro/image-to-video
About
MiniMax Hailuo-02 Image To Video API (Pro, 1080p): Advanced image-to-video generation model with 1080p resolution

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/minimax/hailuo-02/pro/image-to-video", {
  input: {
    prompt: "Man walked into winter cave with polar bear",
    image_url: "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/minimax/hailuo-02/pro/image-to-video", {
  input: {
    prompt: "Man walked into winter cave with polar bear",
    image_url: "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/minimax/hailuo-02/pro/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/minimax/hailuo-02/pro/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true


{
  "prompt": "Man walked into winter cave with polar bear",
  "image_url": "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png",
  "prompt_optimizer": true
}
Output
#
video File
The generated video


{
  "video": {
    "file_size": 977790,
    "file_name": "output.mp4",
    "content_type": "video/mp4",
    "url": "https://v3.fal.media/files/monkey/xF9OsLwGjjNURyAxD8RM1_output.mp4"
  }
}
Other types
#
TextToSpeechTurboRequest
#
text string
Text to convert to speech (max 5000 characters)

voice_setting VoiceSetting
Voice configuration settings

audio_setting AudioSetting
Audio configuration settings

language_boost LanguageBoostEnum
Enhance recognition of specified languages and dialects

Possible enum values: Chinese, Chinese,Yue, English, Arabic, Russian, Spanish, French, Portuguese, German, Turkish, Dutch, Ukrainian, Vietnamese, Indonesian, Japanese, Italian, Korean, Thai, Polish, Romanian, Greek, Czech, Finnish, Hindi, auto

output_format OutputFormatEnum
Format of the output content (non-streaming only) Default value: "hex"

Possible enum values: url, hex

pronunciation_dict PronunciationDict
Custom pronunciation dictionary for text replacement

TextToVideoLiveRequest
#
prompt string
prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

TextToVideoDirectorRequest
#
prompt string
Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645

prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
URL of the image to use as the first frame

prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

SubjectReferenceRequest
#
prompt string
subject_reference_image_url string
URL of the subject reference image to use for consistent subject appearance

prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

AudioSetting
#
sample_rate SampleRateEnum
Sample rate of generated audio Default value: "32000"

Possible enum values: 8000, 16000, 22050, 24000, 32000, 44100

bitrate BitrateEnum
Bitrate of generated audio Default value: "128000"

Possible enum values: 32000, 64000, 128000, 256000

format FormatEnum
Audio format Default value: "mp3"

Possible enum values: mp3, pcm, flac

channel ChannelEnum
Number of audio channels (1=mono, 2=stereo) Default value: "1"

Possible enum values: 1, 2

MiniMaxTextToImageWithReferenceRequest
#
prompt string
Text prompt for image generation (max 1500 characters)

image_url string
URL of the subject reference image to use for consistent character appearance

aspect_ratio AspectRatioEnum
Aspect ratio of the generated image Default value: "1:1"

Possible enum values: 1:1, 16:9, 4:3, 3:2, 2:3, 3:4, 9:16, 21:9

num_images integer
Number of images to generate (1-9) Default value: 1

prompt_optimizer boolean
Whether to enable automatic prompt optimization

MiniMaxTextToImageRequest
#
prompt string
Text prompt for image generation (max 1500 characters)

aspect_ratio AspectRatioEnum
Aspect ratio of the generated image Default value: "1:1"

Possible enum values: 1:1, 16:9, 4:3, 3:2, 2:3, 3:4, 9:16, 21:9

num_images integer
Number of images to generate (1-9) Default value: 1

prompt_optimizer boolean
Whether to enable automatic prompt optimization

VoiceSetting
#
voice_id string
Predefined voice ID to use for synthesis Default value: "Wise_Woman"

speed float
Speech speed (0.5-2.0) Default value: 1

vol float
Volume (0-10) Default value: 1

pitch integer
Voice pitch (-12 to 12)

emotion EmotionEnum
Emotion of the generated speech

Possible enum values: happy, sad, angry, fearful, disgusted, surprised, neutral

english_normalization boolean
Enables English text normalization to improve number reading performance, with a slight increase in latency

VoiceCloneRequest
#
audio_url string
URL of the input audio file for voice cloning. Should be at least 10 seconds long.

noise_reduction boolean
Enable noise reduction for the cloned voice

need_volume_normalization boolean
Enable volume normalization for the cloned voice

accuracy float
Text validation accuracy threshold (0-1)

text string
Text to generate a TTS preview with the cloned voice (optional) Default value: "Hello, this is a preview of your cloned voice! I hope you like it!"

model ModelEnum
TTS model to use for preview. Options: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo Default value: "speech-02-hd"

Possible enum values: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo

VoiceDeleteRequest
#
voice_id string
The voice_id of the voice to be deleted

TextToVideoRequest
#
prompt string
prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

ImageToVideoDirectorRequest
#
prompt string
Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645

image_url string
URL of the image to use as the first frame

prompt_optimizer boolean
Whether to use the model's prompt optimizer Default value: true

TextToSpeechHDRequest
#
text string
Text to convert to speech (max 5000 characters)

voice_setting VoiceSetting
Voice configuration settings

audio_setting AudioSetting
Audio configuration settings

language_boost LanguageBoostEnum
Enhance recognition of specified languages and dialects

Possible enum values: Chinese, Chinese,Yue, English, Arabic, Russian, Spanish, French, Portuguese, German, Turkish, Dutch, Ukrainian, Vietnamese, Indonesian, Japanese, Italian, Korean, Thai, Polish, Romanian, Greek, Czech, Finnish, Hindi, auto

output_format OutputFormatEnum
Format of the output content (non-streaming only) Default value: "hex"

Possible enum values: url, hex

pronunciation_dict PronunciationDict
Custom pronunciation dictionary for text replacement

PronunciationDict
#
tone_list list<string>
List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']

6)fal-ai/kling-video/v2.1/standard/image-to-video
About
Kling 2.1 (std) Image to Video API.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/v2.1/standard/image-to-video", {
  input: {
    prompt: "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
    image_url: "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kling-video/v2.1/standard/image-to-video", {
  input: {
    prompt: "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
    image_url: "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kling-video/v2.1/standard/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kling-video/v2.1/standard/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5


{
  "prompt": "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty",
  "image_url": "https://v3.fal.media/files/panda/W-_J46zuJDQnUhqkKm9Iv_image.webp",
  "duration": "5",
  "negative_prompt": "blur, distort, and low quality",
  "cfg_scale": 0.5
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/panda/aIxNQwcs5syCT5sYT5_HB_output.mp4"
  }
}
Other types
#
TextToVideoV21MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

V1TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

camera_control CameraControlEnum
Camera control parameters

Possible enum values: down_back, forward_up, right_turn_forward, left_turn_forward

advanced_camera_control CameraControl
Advanced Camera control parameters

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ProImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

tail_image_url string
URL of the image to be used for the end of the video

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncA2VRequest
#
video_url string
The URL of the video to generate the lip sync for.

audio_url string
The URL of the audio to generate the lip sync for.

ImageToVideoV21MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

CameraControl
#
movement_type MovementTypeEnum
The type of camera movement

Possible enum values: horizontal, vertical, pan, tilt, roll, zoom

movement_value integer
The value of the camera movement

ImageToVideoV21ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncT2VRequest
#
video_url string
The URL of the video to generate the lip sync for.

text string
Text content for lip-sync video generation. Max 120 characters.

voice_id VoiceIdEnum
Voice ID to use for speech synthesis

Possible enum values: genshin_vindi2, zhinen_xuesheng, AOT, ai_shatang, genshin_klee2, genshin_kirara, ai_kaiya, oversea_male1, ai_chenjiahao_712, girlfriend_4_speech02, chat1_female_new-3, chat_0407_5-1, cartoon-boy-07, uk_boy1, cartoon-girl-01, PeppaPig_platform, ai_huangzhong_712, ai_huangyaoshi_712, ai_laoguowang_712, chengshu_jiejie, you_pingjing, calm_story1, uk_man2, laopopo_speech02, heainainai_speech02, reader_en_m-v1, commercial_lady_en_f-v1, tiyuxi_xuedi, tiexin_nanyou, girlfriend_1_speech02, girlfriend_2_speech02, zhuxi_speech02, uk_oldman3, dongbeilaotie_speech02, chongqingxiaohuo_speech02, chuanmeizi_speech02, chaoshandashu_speech02, ai_taiwan_man2_speech02, xianzhanggui_speech02, tianjinjiejie_speech02, diyinnansang_DB_CN_M_04-v2, yizhipiannan-v1, guanxiaofang-v2, tianmeixuemei-v1, daopianyansang-v1, mengwa-v1

voice_language VoiceLanguageEnum
The voice language corresponding to the Voice ID Default value: "en"

Possible enum values: zh, en

voice_speed float
Speech rate for Text to Video generation Default value: 1

V1ImageToVideoRequest
#
prompt string
The prompt for the video

image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

static_mask_url string
URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)

dynamic_masks list<DynamicMask>
List of dynamic masks

DynamicMask
#
mask_url string
URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)

trajectories list<Trajectory>
List of trajectories

TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

VideoEffectsRequest
#
input_image_urls list<string>
URL of images to be used for hug, kiss or heart_gesture video.

effect_scene EffectSceneEnum
The effect scene to use for the video generation

Possible enum values: hug, kiss, heart_gesture, squish, expansion, fuzzyfuzzy, bloombloom, dizzydizzy

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

MultiImageToVideoRequest
#
prompt string
input_image_urls list<string>
List of image URLs to use for video generation. Supports up to 4 images.

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

TextToVideoV2MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

Trajectory
#
x integer
X coordinate of the motion trajectory

y integer
Y coordinate of the motion trajectory

ImageToVideoV2MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

7)fal-ai/wan-i2v
About
Inference

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/wan-i2v", {
  input: {
    prompt: "Cars racing in slow motion",
    image_url: "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/wan-i2v", {
  input: {
    prompt: "Cars racing in slow motion",
    image_url: "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/wan-i2v", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/wan-i2v", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt to guide video generation.

negative_prompt string
Negative prompt for video generation. Default value: "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"

image_url string
URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.

num_frames integer
Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units. Default value: 81

frames_per_second integer
Frames per second of the generated video. Must be between 5 to 24. Default value: 16

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

resolution ResolutionEnum
Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit. Default value: "720p"

Possible enum values: 480p, 720p

num_inference_steps integer
Number of inference steps for sampling. Higher values give better quality but take longer. Default value: 30

guide_scale float
Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality. Default value: 5

shift float
Shift parameter for video generation. Default value: 5

enable_safety_checker boolean
If set to true, the safety checker will be enabled.

enable_prompt_expansion boolean
Whether to enable prompt expansion.

acceleration AccelerationEnum
Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'. Default value: "regular"

Possible enum values: none, regular

aspect_ratio AspectRatioEnum
Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image. Default value: "auto"

Possible enum values: auto, 16:9, 9:16, 1:1


{
  "prompt": "Cars racing in slow motion",
  "negative_prompt": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
  "image_url": "https://storage.googleapis.com/falserverless/gallery/car_720p.png",
  "num_frames": 81,
  "frames_per_second": 16,
  "resolution": "720p",
  "num_inference_steps": 30,
  "guide_scale": 5,
  "shift": 5,
  "enable_safety_checker": true,
  "enable_prompt_expansion": false,
  "acceleration": "regular",
  "aspect_ratio": "auto"
}
Output
#
video File
The generated video file.

seed integer
The seed used for generation.


{
  "video": {
    "url": "https://storage.googleapis.com/falserverless/gallery/wan-i2v-example.mp4"
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

8)fal-ai/pixverse/v4.5/image-to-video
About
Image To Video V4 5

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/pixverse/v4.5/image-to-video", {
  input: {
    prompt: "A woman warrior with her hammer walking with his glacier wolf.",
    image_url: "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/pixverse/v4.5/image-to-video", {
  input: {
    prompt: "A woman warrior with her hammer walking with his glacier wolf.",
    image_url: "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/pixverse/v4.5/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/pixverse/v4.5/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame


{
  "prompt": "A woman warrior with her hammer walking with his glacier wolf.",
  "aspect_ratio": "16:9",
  "resolution": "720p",
  "duration": "5",
  "negative_prompt": "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded",
  "image_url": "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
}
Output
#
video File
The generated video


{
  "video": {
    "file_size": 6420765,
    "file_name": "output.mp4",
    "content_type": "video/mp4",
    "url": "https://fal.media/files/koala/HEWK7BBwqWrz7F5nAZzp7_output.mp4"
  }
}
Other types
#
ExtendRequest
#
video_url string
URL of the input video to extend

prompt string
Prompt describing how to extend the video

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the extended video

Possible enum values: anime, 3d_animation, day, cyberpunk, comic

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

model ModelEnum
The model version to use for generation Default value: "v4.5"

Possible enum values: v3.5, v4, v4.5

seed integer
Random seed for generation

TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

FastTextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

ImageToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

TransitionRequest
#
prompt string
The prompt for the transition

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

first_image_url string
URL of the image to use as the first frame

last_image_url string
URL of the image to use as the last frame

FastImageToVideoRequestV4
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

VideoOutputV4
#
video File
The generated video

SoundEffectRequest
#
video_url string
URL of the input video to add sound effects to

original_sound_switch boolean
Whether to keep the original audio from the video

prompt string
Description of the sound effect to generate. If empty, a random sound effect will be generated Default value: ""

LipsyncRequest
#
video_url string
URL of the input video

audio_url string
URL of the input audio. If not provided, TTS will be used.

voice_id VoiceIdEnum
Voice to use for TTS when audio_url is not provided Default value: "Auto"

Possible enum values: Emily, James, Isabella, Liam, Chloe, Adrian, Harper, Ava, Sophia, Julia, Mason, Jack, Oliver, Ethan, Auto

text string
Text content for TTS when audio_url is not provided

FastImageToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

FastExtendRequest
#
video_url string
URL of the input video to extend

prompt string
Prompt describing how to extend the video

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the extended video

Possible enum values: anime, 3d_animation, day, cyberpunk, comic

resolution ResolutionEnum
The resolution of the generated video. Fast mode doesn't support 1080p Default value: "720p"

Possible enum values: 360p, 540p, 720p

model ModelEnum
The model version to use for generation Default value: "v4.5"

Possible enum values: v3.5, v4, v4.5

seed integer
Random seed for generation

fal-ai/luma-dream-machine/ray-2-flash/image-to-video
About
Luma's state of the art Ray2 model for image-to-video generation.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s


{
  "prompt": "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
  "image_url": "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg",
  "aspect_ratio": "16:9",
  "resolution": "540p",
  "duration": "5s"
}
Output
#
video File
URL of the generated video


{
  "video": {
    "url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

10)fal-ai/magi-distilled/image-to-video
About
Generate a video from an image.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/magi-distilled/image-to-video", {
  input: {
    prompt: "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins to pull back out over the ocean. Finally, the camera sinks below the waves deeply, fading to dark blue and finally to black.",
    image_url: "https://raw.githubusercontent.com/painebenjamin/pointy-seeds/refs/heads/main/captain-start.jpg"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/magi-distilled/image-to-video", {
  input: {
    prompt: "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins to pull back out over the ocean. Finally, the camera sinks below the waves deeply, fading to dark blue and finally to black.",
    image_url: "https://raw.githubusercontent.com/painebenjamin/pointy-seeds/refs/heads/main/captain-start.jpg"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/magi-distilled/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/magi-distilled/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt to guide video generation.

image_url string
URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.

num_frames integer
Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit. Default value: 96

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

resolution ResolutionEnum
Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit. Default value: "720p"

Possible enum values: 480p, 720p

num_inference_steps NumInferenceStepsEnum
Number of inference steps for sampling. Higher values give better quality but take longer. Default value: "16"

Possible enum values: 4, 8, 16, 32

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

aspect_ratio AspectRatioEnum
Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image. Default value: "auto"

Possible enum values: auto, 16:9, 9:16, 1:1


{
  "prompt": "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins to pull back out over the ocean. Finally, the camera sinks below the waves deeply, fading to dark blue and finally to black.",
  "image_url": "https://raw.githubusercontent.com/painebenjamin/pointy-seeds/refs/heads/main/captain-start.jpg",
  "num_frames": 96,
  "resolution": "720p",
  "num_inference_steps": 16,
  "enable_safety_checker": true,
  "aspect_ratio": "auto"
}
Output
#
video File
The generated video file.

seed integer
The seed used for generation.


{
  "video": {
    "url": "https://v3.fal.media/files/zebra/3XmM6yIGZEWxwbbDyTkhw_391bee80-b756-425d-b74c-f9083c7eec4f.mp4"
  }
}
Other types
#
MagiResponse
#
video File
The generated video file.

seed integer
The seed used for generation.

MagiTextToVideoRequest
#
prompt string
The text prompt to guide video generation.

num_frames integer
Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit. Default value: 96

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

resolution ResolutionEnum
Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit. Default value: "720p"

Possible enum values: 480p, 720p

num_inference_steps NumInferenceStepsEnum
Number of inference steps for sampling. Higher values give better quality but take longer. Default value: "16"

Possible enum values: 4, 8, 16, 32

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

aspect_ratio AspectRatioEnum
Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image. Default value: "auto"

Possible enum values: auto, 16:9, 9:16, 1:1

MagiVideoExtensionResponse
#
video File
The generated video file.

seed integer
The seed used for generation.

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

MagiVideoExtensionRequest
#
prompt string
The text prompt to guide video generation.

video_url string
URL of the input video to represent the beginning of the video. If the input video does not match the chosen aspect ratio, it is resized and center cropped.

num_frames integer
Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit. Default value: 96

start_frame integer
The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

resolution ResolutionEnum
Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit. Default value: "720p"

Possible enum values: 480p, 720p

num_inference_steps NumInferenceStepsEnum
Number of inference steps for sampling. Higher values give better quality but take longer. Default value: "16"

Possible enum values: 4, 8, 16, 32

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

aspect_ratio AspectRatioEnum
Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image. Default value: "auto"

Possible enum values: auto, 16:9, 9:16, 1:1


